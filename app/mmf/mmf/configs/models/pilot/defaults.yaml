model_config:
  pilot:
    # Type of bert model
    bert_model_name: bert-base-uncased
    direct_features_input: false
    # Dimension of the embedding finally returned by the modal encoder
    modal_hidden_size: 2048
    # Dimension of the embedding finally returned by the text encoder
    text_hidden_size: 768



    # resnet50, see experiments for more options
    image_encoder:
      type: torchvision_resnet
      params:
        name: resnet50
        pretrained: true
        pool_type: avg
        num_output_features: 1
        zero_init_residual: false

    text_encoder:
      type: any_transformer
      params:
        name: distilbert-base-uncased
        dim: 768
        num_hidden_layers: 12
        num_attention_heads: 12




    classifier:
      type: mlp
      params:
        # image dim + text dim, in this case 2048 + 768 in case of features
        in_dim: 2816 # default for pipeline
        out_dim: 2250 # target size for okvqa answer vocabulary
        hidden_dim: 2533 # average of input and output, r.o.t.
        num_layers: 2 # r.o.t.